\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{mathtools}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{microtype}
\usepackage{float}
\usepackage{listings}
\usepackage{color}

% Establecer márgenes
\geometry{a4paper, margin=1in, top=1.2in, headheight=15pt}

% Configurar hipervínculos
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=blue,
    citecolor=blue,
    urlcolor=blue,
    pdftitle={Práctica 1},
    pdfauthor={Renato Bedriñana Cárdenas, Hugo Blanco Demelo},
    pdfsubject={Práctica 1 - Sampling and Quantization},
}

% Configuración de encabezado y pie de página
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\footnotesize Práctica 1}
\fancyhead[R]{\footnotesize Sampling and Quantization}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

% Configuración para código fuente
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}

\lstset{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\small,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

% Formato de títulos
\titleformat{\section}
  {\normalfont\large\bfseries\color{blue!70!black}}
  {\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\normalsize\bfseries\color{blue!60!black}}
  {\thesubsection}{1em}{}

% Espacio después de secciones
\titlespacing*{\section}{0pt}{3.5ex plus 1ex minus .2ex}{2.3ex plus .2ex}
\titlespacing*{\subsection}{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

% Definición de comandos para matemáticas
\newcommand{\dB}{\text{dB}}
\newcommand{\dBFS}{\text{dBFS}}

% Información del documento
\title{\vspace{-1.5cm}\Large\textbf{Práctica 1: Sampling and Quantization}}
\author{\normalsize Renato Bedriñana Cárdenas \and \normalsize Hugo Blanco Demelo}
\date{\normalsize\today}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\begin{document}

\maketitle
\section{Task 1}
\textbf{Question: Give your interpretation of the resulting graphs. Do the quantization levels correspond with the values you had expected?}

\vspace{0.5cm}

In Figure~\ref{fig:task1_2}, we can observe the continuous signal x (blue) and the 2 quantized version using 2 (red) and 4 (yellow) bits.
As expected, the 2 bit quantization produces fewer discrete levels than the 4 bits quantization.
Increase the number of bits decreases $\Delta$, resulting in smaller steps and a quantized signal that follows the input more closely.

\begin{figure}[H]  % H is fot NOT letting latex insert the image in another place
    \centering
    \includegraphics[width=1\textwidth]{img/task1_2.png}
    \caption{Quantization error for N=2 (red) and N=4 (yellow)}
    \label{fig:task1_2}
\end{figure}

\vspace{1cm}
\textbf{Question: For both cases, represent the quantization error as a function of input amplitude in the range $[-7, +7]$ and comment on your results. Is this error always within the $[-\Delta /2, +\Delta /2]$ interval?}

\vspace{0.5cm}
The magnitude of the error decreases as the number of bits increases, since a smaller quantization step
$\Delta$ reduces the maximum deviation between the input and its quantized version.
The $[-\Delta /2, +\Delta /2]$ in each case is as follows:
\begin{itemize}
    \item For N = 2 the $\Delta$ value we get is $\Delta = 3.5$, so the interval should be $[-1.75, 1.75]$.
    \item For N = 4 the $\Delta$ value we get is $\Delta = 0.875$, so the interval should be $[-0.4375, 0.4375]$.
\end{itemize}
In both cases, the error remains bounded within the theoretical interval $[-\Delta /2, +\Delta /2]$.

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{img/task1_2_2.png}
    % \caption{Description of your image}
    \label{fig:task1_2_2}
\end{figure}

\section{Task 2}
\textbf{Question: Assume a full-scale sinusoidal input and plot the histogram of the quantization error. Do you observe what you expected, or not?}

\vspace{0.5cm}
Due we have an amplitude equal to FS we can expect clipping. We have $\Delta= \frac{2*FS}{2^N} = 0.0098$, the $[-\frac{\Delta}{2}, +\frac{\Delta}{2}]$ interval should be uniformly distributed (while the input does not get clipped) between $[-0.0049, +0.0049]$.
In the histogram we can see that in that interval the error is uniformly distributed, but there is an error tail in the positive extreme.
It means that there is \textbf{clipping} in the positive.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{img/task2_1.png}
    % \caption{Description of your image}
    \label{fig:task2_1}
\end{figure}

\vspace{1cm}
\textbf{Question: Explain the operation of the Matlab command var. Estimate the variance of the quantization error using var,
    and compare it to its theoretical value. Estimate the value (in dB) of the Signal to-Quantization Noise Ratio (SQNR)
    and compare it to its theoretical value.
}

\vspace{0.5cm}
The MATLAB command \texttt{var} computes the variance of a set of values. For a vector $x$, it calculates:
$\text{var}(x) = \frac{1}{n-1}\sum_{i=1}^n (x_i - \bar{x})^2$, where $\bar{x}$ is the mean of the values in $x$ and $n$ is the total number of samples.
We used \texttt{var(x,1)} to compute the population variance (divide by n).

The empiral value of the variance of the quantization error we got is $8.72123e-06$, and the theoretical value is $\frac{\Delta^2}{12} = 7.94729e-06$.

The estimated value of the SQNR in dB we got is $61.5633$ dB, and the theoretical value is $61.9597$ dB.

\vspace{1cm}
\textbf{Question: Repeat the previous steps for sinusoids with different amplitudes, and with decreasing resolutions
    of 12, 10, 8, 6 and 4 bits, in order to fill Table 1, rounding the SQNR values (in dB) to two
    decimal places. Comment on your results.
}

\vspace{0.5cm}
\begin{table}[H]
    \centering
    \begin{tabular}{|c||c|c|c|c|c|c|c|c|}
        \hline
                    & \multicolumn{2}{c|}{$A=0.5\cdot\text{\tt FS}$} & \multicolumn{2}{c|}{$A=0.75\cdot\text{\tt FS}$} & \multicolumn{2}{c|}{$A=\text{\tt FS}$} & \multicolumn{2}{c|}{$A=1.03\cdot\text{\tt FS}$}                                          \\
        \cline{2-9} & \multicolumn{2}{ |c| }{SQNR (dB)}              & \multicolumn{2}{ |c| }{SQNR (dB)}               & \multicolumn{2}{ |c| }{SQNR (dB)}      & \multicolumn{2}{ |c| }{SQNR (dB)}                                                        \\
        \hline
        $N$         & theory                                         & measured                                        & theory                                 & measured                                        & theory  & measured & theory & measured \\
        \hline\hline
        12          & 67.98                                          & 68.03                                           & 71.5                                   & 71.54                                           & 74.00   & 73.7     & 74.26  & 38.47    \\
        \hline
        10          & 55.94                                          & 56.01                                           & 59.46                                  & 59.53                                           & 61.96   & 61.56    & 62.22  & 38.19    \\
        \hline
        8           & 43.90                                          & 44.04                                           & 47.42                                  & 47.53                                           & 49.92   & 49.15    & 50.18  & 36.97    \\
        \hline
        6           & 31.86                                          & 32.13                                           & 35.38                                  & 35.6                                            & 37.88   & 36.52    & 38.14  & 32.27    \\
        \hline
        4           & 19.82                                          & 20.37                                           & 23.34                                  & 23.78                                           & 25.8397 & 23.63    & 26.1   & 22.53    \\
        \hline
    \end{tabular}
    \caption{Pertaining to Task 2.}
    \label{tab:task2}
\end{table}

For amplitudes below FS (0.5*FS and 0.75*FS) the empirical SQNR values closely match the theoretical predictions.
For an amplitude equal to FS, the empirical values still align well with theory, indicating minimal clipping effects.
However, as the amplitude exceeds FS (1.03*FS), discrepancies arise due to clipping effects, SQNR collapses and even adding more bits does not solve the problem.

As the number of bits decreases the variance of the error grows roughly as expected and SQNR drops approximately 6 dB/bit.
For moderate amplitudes the theory remains a good approximation down to mid-low N (but deviations increases as N gets smaller).

\section{Task 3}
\textbf{Question: Suppose that you have an N-bit A/D converter with tunable FS, and you know that your input samples follow
    a symmetric triangular pdf in some interval $[-x_0,x_0]$. Intuitively, how would you set the FS value of your converter?
    What would the resulting rms value $\sigma_x$ in dBFS be?
}

\vspace{0.5cm}
If you set $FS < x_0$ any imput $|x|$ greater than FS will be clipped. If $FS > x_0$,we would be wasting the converter's since the signal would never
reach the limits. Therefore, the value of FS should be $x_0$.

To reach the variance of a symmetric triangular distribution we need to make some calculations:
\[
    Var(x) = E[x^2] - (E[x])^2 = E[x^2] + 0 = \int_{-x_0}^{x_0} x^2 f(x) dx = x_0^2/6
\]

$\sigma_x = \sqrt{var(x)} = \frac{x_0}{\sqrt{6}}$ and in dBFS (with $x_0$ = FS) would be $20\log_{10}(1/\sqrt{6}) = -7,78$ dBFS.

\vspace{1cm}
\textbf{Question: Explain how to generate in Matlab samples of a random variable following a symmetric triangular pdf with
    zero mean and rms value $\sigma_x$. Check the histogram and use the commands mean and var to validate your approach
}

\vspace{0.5cm}
We have two options to do it:
\begin{itemize}
    % uso task3_2.m
    \item Option 1: The easiest way to generate a random variable with triangular pdf is using the function \textit{makedist} from Matlab.
          The function spects the parameters A, B and C that define the triangular distribution.
          So we set the function parameters to get a symmetric triangular distribution centered at 0: \texttt{makedist('Triangular','A',-x0,'B',x0,'C',0)}

          The result of the mean and var commands are as follows:
          \begin{itemize}
              \item Empirical mean: -4.58885e-05, wich is near to 0, very close to our target mean.
              \item Empirical rms value [dBFS]: -7.78072, wich is very close to our target variance.
          \end{itemize}

          \begin{figure}[H]
              \centering
              \includegraphics[width=1\textwidth]{img/task3_tri_mkdist.png}
              \label{fig:task3_tri_mkdist}
          \end{figure}

          To do it, we can use the following code:
          \begin{lstlisting}[language=Matlab]
            x0 = 2;
            A = -x0; B = 0; C = +x0; % simetria = media 0

            pd = makedist('Triangular','A',A,'B',B,'C',C);
            N = 100000;
            samples = random(pd, N, 1);

            % comprobaciones rapidas
            emp_mean = mean(samples);
            emp_var = var(samples);
            emp_desv_std = std(samples);

            % valores teoricos
            % theo_mean = 0; % simetria centrado en 0
            theo_var = (A^2 + B^2 + C^2 - A*B - A*C - B*C)/18;
            rms = 20*log10(sqrt(theo_var)/x0);

            fprintf('Theorical mean: 0; emp mean: %.2f\n',emp_mean);
            fprintf('Theorical var: %.2f; emp var: %.2f\n',theo_var,emp_var);
            fprintf('Sigma value: %.2f\n',sqrt(theo_var));
            fprintf('rms value in dBFS: %.2f\n',rms)

            % ver histograma y pdf teorica
            xgrid = linspace(A,C,500)';
            figure
            histogram(samples,100,'Normalization','pdf')
            hold on
            plot(xgrid, pdf(pd,xgrid), 'LineWidth',1.5)
            title('Triangular (media 0) -- muestras vs PDF')
            hold off
        \end{lstlisting}

          % uso task3_tri.m
    \item Option 2: Another way we can generate samples of a random variable following a symmetric triangular pdf as the sum of two independent random variables $X_1$ and $X_2$ from a uniform distribution.
          When two independent random variables with uniform distributions are added, the resulting probability density function (PDF) becomes triangular. This can be understood both intuitively and mathematically.

          Intuitively, if each variable is uniform on \([-a,a]\), there are many pairs that sum near zero but only a few that produce sums near the extremes \(\pm 2a\). Hence the PDF peaks at zero and decreases linearly towards the edges.

          Mathematically, let \(Z = X_1 + X_2\) with \(X_1,X_2\) independent and uniform on \([-a,a]\). The PDF of \(Z\) is the convolution of the two uniform PDFs:
          \[
              f_Z(z) = (f_{X_1} * f_{X_2})(z) = \int_{-\infty}^{\infty} f_{X_1}(t)\, f_{X_2}(-t + z)\, dt.
          \]
          Carrying out the convolution yields the triangular PDF supported on \([-2a,2a]\):
          \[
              f_Z(z) = \frac{2a - |z|}{4a^{2}}, \qquad |z|\le 2a.
          \]
          If we want the triangular distribution to have support \([-x_0,x_0]\), we must choose \(a = x_0/2\). In that case the PDF simplifies to
          \[
              f_Z(z)=\frac{x_0 - |z|}{x_0^2}, \qquad |z|\le x_0,
          \]
          Adding two uniform random variables with 0 mean, results in another random variable with 0 mean.

          \[
              E[Z] = E[X_1 + X_2] = E[X_1] + E[X_2] = 0 + 0 = 0.
          \]

          The variance of the sum of two independent random variables is the sum of their variances.
          So if we want a triangular distribution with variance $\sigma_x$ (in dBFS), we need to set the variance of each uniform variable to $\sigma_x/2$.

          \[
              Var(Z) = Var(X_1 + X_2) = Var(X_1) + Var(X_2) = \sigma_x/2 + \sigma_x/2 = \sigma_x.
          \]

          For a uniform on \([-a,a]\) we have \(\mathrm{Var}(X_i)=a^{2}/3\). Taking \(a=x_0/2\) gives \(\mathrm{Var}(Z)=2\cdot (x_0/2)^2/3 = x_0^2/6 = \sigma_x\), as required.

          The result of the mean and var commands are as follows:
          \begin{itemize}
              \item Empirical mean: 0.00003, wich is close to 0, very close to our target mean.
              \item Empirical variance [dB]: -7.80701, wich is very close to our target variance.
          \end{itemize}

          \begin{figure}[H]
              \centering
              \includegraphics[width=1\textwidth]{img/task3_tri_sum2uniform.png}
              \label{fig:task3_tri_sum2uniform}
          \end{figure}

          we can doit as follows: REVISAR!!
          \begin{lstlisting}[language=Matlab]
            x0=2;
            sigma0 = x0/sqrt(2);
            N = 100000;
            
            c = sigma0 * sqrt(3/2);

            x1 = (2 * rand(N, 1) - 1) * c;
            x2 = (2 * rand(N, 1) - 1) * c;

            y = x1 + x2;

            sample_mean = mean(y);
            sample_var = var(y);
            sample_rms = std(y);

            fprintf('--- Validation ---\n');
            fprintf('Target Mean: 0.0\n');
            fprintf('Sample Mean: %f\n\n', sample_mean);

            fprintf('Target Variance (sigma0^2): %f\n', sigma0^2);
            fprintf('Sample Variance: %f\n\n', sample_var);

            fprintf('Target RMS (sigma0): %f\n', sigma0);
            fprintf('Sample RMS: %f\n\n', sample_rms);

            figure;
            histogram(y, 100, 'Normalization', 'pdf', 'DisplayName', 'Generated Samples');
            grid on;
            hold on;

            a = 2*c;
            x_pdf = linspace(-a, a, 400);
            y_pdf = (1/a) * (1 - abs(x_pdf)/a);
            plot(x_pdf, y_pdf, 'r-', 'LineWidth', 2.5, 'DisplayName', 'Theoretical PDF');

            title('Symmetric Triangular Distribution');
            xlabel('Random Variable Value');
            ylabel('Probability Density Function (PDF)');
            legend;
            hold off;
        \end{lstlisting}
\end{itemize}

\vspace{1cm}
\textbf{Question: Take $10\cdot 2^{10}$ of these triangularly distributed samples, quantize them, and estimate the SQNR empirically
    for $N=$ 3, 4, 5 and 6 bits. Do this for $\sigma_x$ varying in the range $[-50, 0]$ dBFS and in steps of $0.1$ dBFS. Plot the
    resulting curves (SQNR in dB vs. $\sigma_x$ in dBFS) along with the theoretical expression
    \begin{equation}\label{eq:sqnr}
        {\rm SQNR} = 6.02 N + 4.77-20\log_{10}\frac{\rm FS}{\sigma_x} \qquad \mbox{(dB).}
    \end{equation}
    Are there any differences between the theoretical and empirical curves? If so, how do you explain them?}
\vspace{0.5cm}

\begin{figure}[H]
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/task3_tri_n3.png}
        \caption{N=3 bits - $\sigma_{opt}$=-6.60 dBFS, SQNR=15.36 dB}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/task3_tri_n4.png}
        \caption{N=4 bits - $\sigma_{opt}$=-7.20 dBFS, SQNR=21.56 dB}
    \end{subfigure}

    \medskip

    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/task3_tri_n5.png}
        \caption{N=5 bits - $\sigma_{opt}$=-7.30 dBFS, SQNR=27.52 dB}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/task3_tri_n6.png}
        \caption{N=6 bits - $\sigma_{opt}$=-7.30 dBFS, SQNR=33.47 dB}
    \end{subfigure}

    \caption{SQNR vs $\sigma_x$ (dBFS) for triangularly distributed input at different quantization resolutions.}
    \label{fig:task3_tri_sqnr_vs_sigma}
\end{figure}

The comparison between theoretical and empirical SQNR curves for triangularly distributed inputs is shown in Figure~\ref{fig:task3_tri_sqnr_vs_sigma}.
The red line represents the theoretical SQNR curve, while the blue line represents the empirical SQNR values obtained from quantizing the triangularly distributed samples.

Empirical curves deviate from the straight theoretical line for two practical reasons. At very small $\sigma_x$ values, quantization noise is no longer uniformly distributed and we have no enough bits for quantization.
At large $\sigma_x$ values, clipping occurs, distorting the signal and reducing SQNR below theoretical predictions.
Otherweise, in the mid-range of $\sigma_x$ values, empirical results closely follow theoretical expectations and reaches the maximum SQNR (marked in the description of each image).

When we increase the number of bits N, the curve starts to follow the theorical curve with smaller values of $\sigma_x$.
We reach a point where optimum $\sigma_x$ value (where SQNR is maximized) approaches the theoretical value of -7.78 dBFS calculated earlier.

\vspace{1cm}
\textbf{Question: In view of your results, what are the optimum values (regarding SQNR) of $\sigma_x$ (in dBFS), and for the different resolutions analyzed (3 to 6 bits)?
    Does this agree with your intuition (see first point above)?
}
\vspace{0.5cm}

We can see in the previous plots~\ref{fig:task3_tri_sqnr_vs_sigma} (see the green lines) that the optimum values of $\sigma_x$ (where SQNR is maximized) for different resolutions are:
\begin{itemize}
    \item N=3 bits: $\sigma_{opt}$ = -6.60 dBFS
    \item N=4 bits: $\sigma_{opt}$ = -7.20 dBFS
    \item N=5 bits: $\sigma_{opt}$ = -7.30 dBFS
    \item N=6 bits: $\sigma_{opt}$ = -7.30 dBFS
\end{itemize}
Those are the points where the empirical SQNR reaches its maximum value and then starts to decrease.

The value we calculated in the first point was -7.78 dBFS, which is close to the optimum values we obtained empirically.
If we increase the number of bits, the optimum value gets closer.

\vspace{1cm}
\textbf{Question: Repeat the previous points, but now using normally distributed input samples with zero mean and standard deviation $\sigma_x$.
}
\vspace{0.5cm}

In a Gaussian distribution, we can not set the $[-x_0,x_0]$ limit as in the triangular distribution. So it is a parameter that we can not control and clipping will always occur for some samples no matter how we set FS.
But, we can still set FS to optimize SQNR. Following the definition of dBFS, we can set FS to be some multiple of $\sigma_x$.

\[
    \sigma_x = 20\log_{10}\frac{\sigma_x}{\rm FS} = -20\log_{10}{k} \implies FS = k \cdot \sigma_x
\]

To decide which k value is the best, we have to see the clip probability for each k.
To express the clipping probability in terms of the standard normal CDF, we normalize the Gaussian variable as $Z = X / \sigma_x$, so that $Z \sim \mathcal{N}(0,1)$. Then:
\[
    P(X > FS) = P\!\left(Z > \frac{FS}{\sigma_x}\right) = 1 - \Phi\!\left(k\right),
\]
where $\Phi(k)$ is the cumulative distribution function of the standard normal distribution. Therefore, considering both tails, the total clipping probability is:
\[
    p_{\text{clip}} = 2(1 - \Phi(k)), \quad \text{with } k = \frac{FS}{\sigma_x}.
\]

So we have the next posible values for k:

\begin{itemize}
    \item k = 1: $\sigma_x$ = 0 dBFS (clipping prob = 31.73\%)
    \item k = 2: $\sigma_x$ = -6.02 dBFS (clipping prob = 4.55\%)
    \item k = 3: $\sigma_x$ = -9.54 dBFS (clipping prob = 0.27\%)
    \item k = 4: $\sigma_x$ = -12.04 dBFS (clipping prob = 0.000063\%)
\end{itemize}

A good trade-off between clipping probability and SQNR can be achieved with k = 3, which gives a good compromise between dynamic range usage and distortion.

To generate normally distributed samples we can use the Matlab command \texttt{randn}, which generates samples from a standard normal distribution (mean 0, variance 1).
And then we scale the samples to get the desired standard deviation $\sigma_x$. The output plot is visible in the Figure~\ref{fig:task3_normal_dist}.

% use el código task3_normal_dist_set.m
The result of the mean and var commands are as follows:
\begin{itemize}
    \item Empirical mean: -0.000265784, close to our target mean.
    \item Empirical variance [dB]: -9.56729, again, close to the value we expected.
\end{itemize}

Analyzing the SQNR vs $\sigma_x$ curves in different N levels, we obtain similar outputs as the triangular distribution.
We can check them in the Figure~\ref{fig:task3_normal_sqnr_vs_sigma}, we observe that the empirical SQNR values deviate from the theoretical predictions, especially at higher $\sigma_x$ values.

But we need more level of $\sigma_x$ to reach the optimum point, because of the clipping that occurs in the Gaussian distribution, and we get a fewer maximum SQNR value than in the triangular distribution.
This is produced because the Gaussian distribution has heavier tails, leading to more frequent clipping events at higher $\sigma_x$ levels.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{img/task3_normal_dist.png}
    \caption{Gaussian distribution (normalized)}
    \label{fig:task3_normal_dist}
\end{figure}

\begin{figure}[H]
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/task3_normal_n3.png}
        \caption{N=3 bits - $\sigma_{opt}$=-7.90 dBFS, SQNR=14.03 dB}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/task3_normal_n4.png}
        \caption{N=4 bits - $\sigma_{opt}$=-8.50 dBFS, SQNR=19.44 dB}
    \end{subfigure}

    \medskip

    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/task3_normal_n5.png}
        \caption{N=5 bits - $\sigma_{opt}$=-9.20 dBFS, SQNR=24.79 dB}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/task3_normal_n6.png}
        \caption{N=6 bits - $\sigma_{opt}$=-10.50 dBFS, SQNR=30.16 dB}
    \end{subfigure}

    \caption{SQNR vs $\sigma_x$ (dBFS) for normal distribution input at different quantization resolutions.}
    \label{fig:task3_normal_sqnr_vs_sigma}
\end{figure}

\vspace{0.5cm}
\section{Task 4}
\input{task4}

\vspace{0.5cm}
\section{Task 5}
\input{task5}

\vspace{0.5cm}
\section{Task 6}
\input{task6}

\input{appendix}
\end{document}