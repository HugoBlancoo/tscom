Consider now a scenario in which the pressure sensor may produce erroneous measurements every now and then, in a random fashion.
Under a sensor error event, the measurement is not related to the true pressure, and is just noise. Therefore, we have now
\begin{equation*}\label{eq:xno}
  x_n = \left\{ \begin{array}{cl} c_h s + v_n, & \mbox{if there is no failure,} \\ v_n, & \mbox{if there is a failure.} \end{array}\right.
\end{equation*}
It is assumed that the sensor is equipped with a failure indicator, so that we know whether a sensor error event has taken place or not.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{0.5cm}
\question{Question: Develop the state and measurement equations for this system. Develop the Kalman filter equations, and in view of them, explain how the effect of sensor error events is handled by the filter.}
\vspace{0.5cm}

\subsubsection*{State and Measurement Equations}

Since the fluid level $\ell$ remains constant over time, the state evolution is:
\begin{equation*}
  s_n = s_{n-1},
\end{equation*}
where $s_n = \ell$ (the constant fluid level). In the Kalman filter framework:
\begin{equation*}
  \boxed{s_n = A_n s_{n-1} + u_n, \quad \text{with } A_n = 1, \quad u_n = 0, \quad Q_n = 0.}
\end{equation*}

For the measurement equation, we introduce an indicator variable $\delta_n$:
\begin{equation*}
  \delta_n = \begin{cases}
    1, & \text{if there is no failure at time } n, \\
    0, & \text{if there is a failure at time } n.
  \end{cases}
\end{equation*}

The measurement equation becomes:
\begin{equation*}
  \boxed{x_n = H_n s_n + w_n, \quad \text{with } H_n = \delta_n \cdot c_h, \quad w_n \sim \mathcal{N}(0, \sigma_v^2).}
\end{equation*}

When $\delta_n = 1$ (no failure): $x_n = c_h s_n + v_n$ (normal measurement).
When $\delta_n = 0$ (failure): $x_n = v_n$ (pure noise, independent of $s_n$).

\subsubsection*{Kalman Filter Equations}

The Kalman filter recursion consists of two steps:

\textbf{Prediction step:}
\begin{align}
  \hat{s}_{n|n-1} &= A_n \hat{s}_{n-1|n-1} = \hat{s}_{n-1|n-1}, \\
  P_{n|n-1} &= A_n P_{n-1|n-1} A_n^T + Q_n = P_{n-1|n-1}.
\end{align}

\textbf{Update step:}
\begin{align}
  K_n &= \frac{P_{n|n-1} H_n}{H_n P_{n|n-1} H_n + R_n} = \frac{P_{n|n-1} \cdot \delta_n c_h}{\delta_n^2 c_h^2 P_{n|n-1} + \sigma_v^2}, \\
  \hat{s}_{n|n} &= \hat{s}_{n|n-1} + K_n(x_n - H_n \hat{s}_{n|n-1}), \\
  P_{n|n} &= (1 - K_n H_n)P_{n|n-1}.
\end{align}

\subsubsection*{Handling Sensor Failures}

\textbf{Case 1: No failure ($\delta_n = 1$):} When $H_n = c_h$, the filter operates normally with $K_n > 0$. The measurement is incorporated and uncertainty decreases.

\textbf{Case 2: Failure detected ($\delta_n = 0$):} When $H_n = 0$, we have $K_n = 0$, so:
\begin{equation*}
  \hat{s}_{n|n} = \hat{s}_{n|n-1}, \quad P_{n|n} = P_{n|n-1}.
\end{equation*}

\textbf{Interpretation:} The filter \textbf{completely ignores} failed measurements. Since they contain no information about the state, not updating is optimal.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{0.5cm}
\question{Question: Write a script {\tt kalman\_dc\_errs.m} to simulate it. Use the same values of $\ell$, $\mu_\ell$, $\sigma_\ell$, $\sigma_v$ as in Task~3, (consider only the case $\sigma_\ell = 11$ cm) and assume that failures are random, statistically independent, and taking place with probability $p$.
  Observe what happens for $p=0.15$ and $p=0.85$, and comment on your results.}
\vspace{0.5cm}

We simulate the Kalman filter with a working failure indicator. Simulation parameters: $\mu_\ell = 250$ cm, $\sigma_\ell = 11$ cm, $\ell_{\text{true}} = 340$ cm, $\sigma_v = 25$ mbar, $c_h = 0.85652$ mbar/cm.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.95\textwidth]{img/task4_2_results.png}
  \caption{Kalman filter WITH failure indicator. Top: $p=0.15$. Bottom: $p=0.85$. Left: level estimates. Right: error covariance evolution.}
  \label{fig:task42}
\end{figure}

\subsubsection*{Results and Interpretation}

\textbf{Case $p = 0.15$ (15\% failure rate):}

The estimate (red line, left panel top) rapidly converges from the initial guess (250 cm) to the true value (340 cm) within the first $\approx 30$ samples. The noisy measurements (cyan asterisks) are smoothed effectively. The standard deviation (right panel top) decreases from 11 cm to approximately 0.5 cm, confirming that the filter accumulates information from the reliable measurements.

\textbf{Case $p = 0.85$ (85\% failure rate):}

Despite 85\% of measurements being pure noise, the estimate (red line, left panel bottom) remains centered around the true value (340 cm) throughout the simulation. The Kalman gain becomes zero when $\delta_n = 0$, preventing corrupted measurements from affecting the state. The standard deviation (right panel bottom) converges to approximately 1.5--2 cm due to fewer reliable measurements, but the bias remains negligible.

\textbf{Key observations:}
\begin{itemize}
  \item The indicator-based approach is \textbf{optimal}: it perfectly separates good from bad measurements.
  \item Performance degrades gracefully with failure rate: uncertainty increases, but bias does not.
  \item The filter is robust even at extreme failure rates when the failure indicator is available.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{0.5cm}
\question{Question: Now suppose that the sensor has no failure indicator, and thus we cannot know the time instants at which error events take place. We decide to assume that they {\em never} take place and run the Kalman filter under such assumption. Modify your code accordingly and observe what happens  for $p=0.15$ and $p=0.85$.}
\vspace{0.5cm}

In this scenario, failures are hidden from the filter. The filter mistakenly assumes $H_n = c_h$ for all $n$, even though failures actually occur with probability $p$. This is a severe model mismatch.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.95\textwidth]{img/task4_3_results.png}
  \caption{Kalman filter WITHOUT failure indicator (assumes $p=0$). Top: $p_{\text{actual}}=0.15$. Bottom: $p_{\text{actual}}=0.85$. Note the divergence at high failure rates.}
  \label{fig:task43}
\end{figure}

\subsubsection*{Results and Interpretation}

\textbf{Case $p = 0.15$ (15\% failure rate):}

The estimate (red line, left panel top) converges to approximately the true value, with slightly more oscillation than in Task 4.2. Since most measurements are reliable, the occasional corrupted ones have limited overall impact. The standard deviation (right panel) follows a similar decreasing trend as Task 4.2.

\textbf{Case $p = 0.85$ (85\% failure rate) --- SEVERE DIVERGENCE:}

\textbf{Observed divergence due to model mismatch:} The estimate (red line, left panel bottom) diverges from the true level when p = 0.85. In the first iterations the filter receives mostly pure noise from failed measurements, but, since failures are not modelled, it interprets this noise as valid information about the state and updates accordingly. This produces a large bias while the internal covariance keeps decreasing, illustrating filter inconsistency.

The standard deviation (right panel bottom) continues to \textit{decrease}, indicating increasing filter confidence. However, this is \textbf{unjustified}---the estimate is severely biased. This is \textbf{filter inconsistency}: the covariance does not reflect the actual error magnitude.

\textbf{Key observations:}
\begin{itemize}
  \item This demonstrates \textbf{filter divergence} from model mismatch.
  \item At high failure rates, blindly trusting all measurements is catastrophic.
  \item The filter's internal covariance becomes \textbf{inconsistent} with the true error.
  \item Even at moderate failure rates ($p=0.15$), performance degradation is noticeable.
\end{itemize}

\textbf{Conclusion:} Without a failure indicator, the Kalman filter is vulnerable. High failure rates cause divergence to biased solutions with overly optimistic uncertainty bounds.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{0.5cm}
\question{Question: Assuming we know $p$, can you think of any trick to improve the performance of the Kalman filter in the situation from the previous point? [Hint: think of the measurement equation having a measurement matrix which is now random, and consider replacing in the Kalman filter its actual value (which is unknown) by its expected value]. Try it out and comment on your results.}
\vspace{0.5cm}

\subsubsection*{Proposed Trick: Expected Measurement Matrix}

When the failure indicator is unavailable, replace the unknown $H_n = \delta_n c_h$ by its expected value:
\begin{equation*}
  H_n^{\text{eff}} = \mathbb{E}[H_n] = c_h(1-p).
\end{equation*}

This de-weights measurements proportionally to the failure probability.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.95\textwidth]{img/task4_4_results.png}
  \caption{Robust filter using $H_n^{\text{eff}} = c_h(1-p)$. Top: $p=0.15$. Bottom: $p=0.85$. Compares favorably to Task 4.3.}
  \label{fig:task44}
\end{figure}

\subsubsection*{Results and Interpretation}

\textbf{Case $p = 0.15$:}

Performance is similar to Task 4.3. The estimate converges accurately. At low failure rates, knowledge of $p$ provides only marginal improvement.

\textbf{Case $p = 0.85$ --- PARTIAL RECOVERY:}

The estimate (red line, left panel) no longer diverges catastrophically as in Task 4.3. Instead, it oscillates around a value closer to the true level (340 cm), with noticeable bias but without the extreme divergence. By de-weighting measurements with $H_n^{\text{eff}} = 0.15 \cdot c_h$, the filter trusts the data less, preventing misleading noise from dominating the estimate.

\subsubsection*{Summary Table}

\begin{table}[h!]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    \textbf{Method} & \textbf{$p=0.15$} & \textbf{$p=0.85$} & \textbf{Robustness} \\
    \hline
    Task 4.2 (With indicator) & Excellent & Excellent & \textbf{Optimal} \\
    Task 4.3 (Assumes $p=0$) & Good & Diverges & Poor \\
    Task 4.4 ($H_n^{\text{eff}}$) & Good & Recovers & Better \\
    \hline
  \end{tabular}
\end{table}

\textbf{Conclusion:} Knowledge of $p$ allows a pragmatic robust filter that avoids catastrophic divergence. However, it remains suboptimal compared to having the actual failure indicator. This demonstrates the critical importance of measurement metadata in sensor fusion.
